n = n(),
disparity = max(E_PCI, na.rm = TRUE) / min(E_PCI, na.rm = TRUE)) |>
suppressMessages()
```
rm()
ctd = dd |>
group_by(STATE_COUNTY) |>
summarize(
n = n(),
disparity = max(E_PCI, na.rm = TRUE) / min(E_PCI, na.rm = TRUE)) |>
suppressMessages()
ggplot(ctd, aes(x = log(n), y = log(disparity))) +
geom_point() +
theme_bw()
library(randomForestSRC)
mf = model.frame(log(disparity) ~ log(n), data = ctd)
fit = rfsrc(log(disparity) ~ log(n), data = mf)
?rfsrc
mf
mf = model.frame(log_disparity ~ log_nFIPS, data = ctd)
ctd$log_disparity <- log(ctd$disparity)
ctd$log_nFIPS <- log(ctd$n)
mf = model.frame(log_disparity ~ log_nFIPS, data = ctd)
fit = rfsrc(log_disparity ~ log_nFIPS, data = mf)
which(mf$residual==max(mf$residual))
ctd[which(mf$residual==max(mf$residual))]
ctd[which(mf$residual==max(mf$residual)), 1]
mf$residual = mf$log_disparity - fit$predicted
ctd[which(mf$residual==max(mf$residual)), 1]
ctd[which(mf$residual==max(mf$residual))]
ctd[which(mf$residual==max(mf$residual)), 1]
which(mf$residual==max(mf$residual))
mf$residual==max(mf$residual)
ctd
d
dd
ctd[which(mf$residual==max(mf$residual)), 1]
sd <- dd |>
filter(STATE = "COLORADO") |>
summarize(
disparity = max(E_PCI, na.rm = TRUE) / min(E_PCI, na.rm = TRUE)) |>
suppressMessages()
sd <- dd |>
filter(STATE == "COLORADO") |>
summarize(
disparity = max(E_PCI, na.rm = TRUE) / min(E_PCI, na.rm = TRUE)) |>
suppressMessages()
ggplot(sd, aes(geometry = geometry, fill = disparity)) +
geom_sf() +
theme_bw()
sd <- dd |>
filter(STATE == "COLORADO") |>
summarize(
disparity = max(E_PCI, na.rm = TRUE) / min(E_PCI, na.rm = TRUE)) |>
suppressMessages()
ggplot(sd, aes(geometry = geometry, fill = log(disparity))) +
geom_sf() +
theme_bw()
sd <- dd |>
filter(STATE == "COLORADO") |>
group_by(COUNTY)
summarize(
disparity = max(E_PCI, na.rm = TRUE) / min(E_PCI, na.rm = TRUE)) |>
suppressMessages()
sd <- dd |>
filter(STATE == "COLORADO") |>
group_by(COUNTY) |>
summarize(
disparity = max(E_PCI, na.rm = TRUE) / min(E_PCI, na.rm = TRUE)) |>
suppressMessages()
ggplot(sd, aes(geometry = geometry, fill = log(disparity))) +
geom_sf() +
theme_bw()
ggplot(sd, aes(geometry = geometry, fill = disparity)) +
geom_sf() +
theme_bw()
ggplot(sd, aes(geometry = geometry, fill = log(disparity))) +
geom_sf() +
theme_bw()
# d: from lecture 9-06
library(sf)
d <- read_sf(file.path("..", "2018-data", "SVI2018_US_tract.shp"))
d |>
as_tibble() |> # can prevent `summarise()` has grouped output by 'STATE'
group_by(STATE, COUNTY) |>
summarize(n = n())
library(readr)
library(DT)
library(dplyr)
d |>
as_tibble() |> # can prevent `summarise()` has grouped output by 'STATE'
group_by(STATE, COUNTY) |>
summarize(n = n())
d |>
# can prevent `summarise()` has grouped output by 'STATE'
group_by(STATE, COUNTY) |>
summarize(n = n())
d |>
as_tibble() |>
group_by(STATE, COUNTY) |>
summarize(n = n())
# `summarise()` has grouped output by 'STATE'
library(haven)
library(purrr)
trial_path = file.path("..", "2023-09-11", "NCT00364013")
trial_files = list.files(trial_path, pattern = "*_pds2019.sas7bdat")
dl = map(file.path(trial_path, trial_files), ~ read_sas(.x))
names(dl) = gsub("*_pds2019.sas7bdat", "", trial_files)
library(haven)
library(purrr)
trial_path = file.path("..", "BIS 620", "NCT00364013")
trial_files = list.files(trial_path, pattern = "*_pds2019.sas7bdat")
dl = map(file.path(trial_path, trial_files), ~ read_sas(.x))
names(dl) = gsub("*_pds2019.sas7bdat", "", trial_files)
View(dl)
library(haven)
library(purrr)
trial_path = file.path("..", "NCT00364013", "PDS_DSA_20050203")
trial_files = list.files(trial_path, pattern = "*_pds2019.sas7bdat")
dl = map(file.path(trial_path, trial_files), ~ read_sas(.x))
names(dl) = gsub("*_pds2019.sas7bdat", "", trial_files)
library(gtsummary)
dl$adsl |>
select(TRT, DTH, AGE, SEX, B_WEIGHT, B_HEIGHT, RACE) |>
tbl_summary(by = TRT)
a = dl$adsl
attributes(a$B_WEIGHT) = list(label = "Baseline")
a |>
select(B_WEIGHT, TRT) |>
tbl_summary(by = TRT)
library(ggplot2)
library(dplyr)
ae = dl$adae
ae |>
group_by(AEPT) |>
summarize(n = n()) |>
ggplot(aes(x = AEPT, y = n)) +
geom_col()
ae %>%
filter(SUBJID == "000003")
# some checks
ae$AEPT %>%
unique() %>%
length()
ae |>
group_by(AEPT) |>
summarize(n = n()) |>
ggplot(aes(x = AEPT, y = n)) +
geom_col()
ae |>
group_by(AEPT) |>
summarize(n = n()) |>
ggplot(aes(x = AEPT, y = n)) +
geom_col() +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ae |>
group_by(AEPT) |>
summarize(n = n()) |>
desc(n) |>
tail(10)
ae |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(avg_across_aparatus)) |>
tail(10)
arrange(desc(n) |>
ae |>
ae |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(n)) |>
tail(10)
d
ae |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(n))
ae |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(n)) |>
tail(2)
ae |>
mutate(AEPT = fct_lump_prop(AEPT, prop = 0.001)) |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(n)) |>
mutate(aept = factor(AEPT, levels = AEPT)) |>
ggplot(aes(x = aept, y = n)) +
geom_col() +
theme_bw() +
theme(axis.text.x = element_text(angle = 270, hjust = 0)) +
scale_y_log10()
library(forcats)
ae |>
mutate(AEPT = fct_lump_prop(AEPT, prop = 0.001)) |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(n)) |>
mutate(aept = factor(AEPT, levels = AEPT)) |>
ggplot(aes(x = aept, y = n)) +
geom_col() +
theme_bw() +
theme(axis.text.x = element_text(angle = 270, hjust = 0)) +
scale_y_log10()
p = x |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(n)) |>
mutate(aept = factor(AEPT, levels = AEPT)) |>
ggplot(aes(x = aept, y = n)) +
geom_col() +
theme_bw() +
theme(axis.text.x = element_text(angle = 270, hjust = 0))
a
plot_ae_counts = function(x) {
p = x |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(n)) |>
mutate(aept = factor(AEPT, levels = AEPT)) |>
ggplot(aes(x = aept, y = n)) +
geom_col() +
theme_bw() +
theme(axis.text.x = element_text(angle = 270, hjust = 0))
p
}
ae |>
filter(SUBJID == "000007") |>
plot_ae_counts()
ae |>
mutate(AEPT = fct_lump_prop(AEPT, prop = 0.001)) |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(n)) |>
mutate(aept = factor(AEPT, levels = AEPT)) |>
ggplot(aes(x = aept, y = n)) +
geom_col() +
theme_bw() +
theme(axis.text.x = element_text(angle = 270, hjust = 0)) + # make horizontal adjustment
scale_y_log10()
?fct_lump_prop
## eg.
quote(ae |>
mutate(AEPT = fct_lump_prop(AEPT, prop = 0.001)))
quote(ae |>
mutate(AEPT = fct_lump_prop(AEPT, prop = 0.001)) |>
group_by(AEPT) |>
summarize(n = n()) |>
arrange(desc(n)) |>
mutate(aept = factor(AEPT, levels = AEPT)))
library(survival)
library(survminer)
demo = demo |> filter(BMMTR1 %in% c("Mutant", "Wild-type"))
library(dplyr)
demo = left_join(dl$adsl, dl$biomark, by = "SUBJID")
demo$arm = paste(demo$TRT, demo$BMMTR1)
demo |>
filter(BMMTR1 %in% c("Mutant", "Wild-type")) |>
select(arm, DTH, AGE, SEX, B_WEIGHT, B_HEIGHT, RACE) |>
tbl_summary(by = "arm")
demo = demo |> filter(BMMTR1 %in% c("Mutant", "Wild-type"))
# Create a KM plot
ggsurvplot(survfit(Surv(DTHDY, DTH) ~ BMMTR1, data = demo), data = demo)
# Create a KM plot
ggsurvplot(survfit(Surv(DTHDY, DTH) ~ BMMTR1, data = demo), data = demo)
ggsurvplot(survfit(Surv(DTHDY, DTH) ~ arm, data = demo),
data = demo, conf.int = TRUE)
library(swimplot)
p = ae[ae$SUBJID == "000007",]
p$AESEVCD = factor(p$AESEVCD, levels = as.character(1:4))
gp = swimmer_plot(
as.data.frame(p),
id = "AEPT",
start = "AESTDYI",
end = "AEENDYI",
name_fill = "AESEVCD")
plot_aes = function(aep) {
aep |>
as.data.frame() |>
mutate(AESEVCD = factor(AESEVCD, levels = as.character(1:4))) |>
swimmer_plot(
id = "AEPT",
start = "AESTDYI",
end = "AEENDYI",
name_fill = "AESEVCD"
)
}
plot_aes(p)
tidyr
?tidy
?tidyr
ae_nest = ae |>
group_by(SUBJID) |>
group_nest(.key = "ae")
library(tidyr)
ae_nest = ae |>
group_by(SUBJID) |>
group_nest(.key = "ae")
library(dplyr)
library(dplyr)
ae_nest = ae |>
group_by(SUBJID) |>
group_nest(.key = "ae")
?group_nest
ae_nest = ae |>
group_by(SUBJID)
ae_nest
ae_nest = ae |>
group_by(SUBJID) |>
group_nest(.key = "ae")
ae_nest
ae_nest
ae_nest[1]
ae_nest[,2]
d = inner_join(dl$adsl, ae_nest, by = "SUBJID")
D
d
names(dae)
dae = inner_join(dl$adsl, ae_nest, by = "SUBJID")
names(dae)
ae_nest_check <- ae_nest %>%
mutate(n = map_int(ae, nrow))
ae_nest_check <- ae_nest %>%
dplyr::mutate(n = map_int(ae, nrow))
?map_int
brary(purrr)
library(purrr)
ae_nest_check <- ae_nest %>%
dplyr::mutate(n = map_int(ae, nrow)) # map_int {purrr}
dae = dae |>
filter(map_lgl(ae, ~ nrow(na.omit(.x)) != 0))
dae = dae |>
filter(map_lgl(ae, ~ nrow(na.omit(.x)) != 0)) |> ## filter out ae is NA?
mutate(ae_plot = map(ae, plot_aes))
dae = dae |>
filter(map_lgl(ae, ~ nrow(na.omit(.x)) != 0))
dae
dae = dae |>
filter(map_lgl(ae, ~ nrow(na.omit(.x)) != 0)) |> ## filter out ae is NAm map_lgl: return T/F
dplyr::mutate(ae_plot = map(ae, plot_aes))
library(swimplot)
dae = dae |>
filter(map_lgl(ae, ~ nrow(na.omit(.x)) != 0)) |> ## filter out ae is NAm map_lgl: return T/F
dplyr::mutate(ae_plot = map(ae, plot_aes))
library(trelliscopejs)
dp = dae |>
filter(map_lgl(ae, negate(is.null))) |>
mutate(ae_plot = map(ae, plot_aes)) |>
select(SUBJID, ae_plot)
trelliscope(x = dp, name = "Adverse Events", panel_col = "ae_plot")
dp = dae |>
# filter(map_lgl(ae, !is.null(.x)))
filter(map_lgl(ae, negate(is.null))) |>
mutate(ae_plot = map(ae, plot_aes)) |>
select(SUBJID, ae_plot, total_ae, worst_ae, ATRT, DTH)
colnames(dae)
# map_dbl
dae$total_ae = map_dbl(dae$ae, nrow)
dae$worst_ae = map_dbl(dae$ae, ~ max(.x$AESEVCD, na.rm = TRUE)) #  .x$AESEVCD not AESEVCD
dp = dae |>
# filter(map_lgl(ae, !is.null(.x)))
filter(map_lgl(ae, negate(is.null))) |>
mutate(ae_plot = map(ae, plot_aes)) |>
select(SUBJID, ae_plot, total_ae, worst_ae, ATRT, DTH)
dp
source("~/Desktop/FALL2023/S&DS 625/case-studies/1-Gymnastics/main.R")
source("./scripts/data.saver.R")
source("~/Desktop/FALL2023/S&DS 625/case-studies/1-Gymnastics/main.R")
source("~/Desktop/FALL2023/S&DS 625/case-studies/1-Gymnastics/main.R", echo=TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
url1 = 'https://www.nbcnews.com/politics/white-house/biden-makes-history-striking-auto-workers-picket-line-rcna117348'
url2 = 'https://abcnews.go.com/Politics/biden-join-striking-auto-workers-picket-line-move/story?id=103470454'
url3 = 'https://www.foxnews.com/us/judge-rules-nyc-migrant-shelter-staten-islands-st-john-villa-academy-must-be-vacated'
url4 = 'https://www.cnn.com/2023/09/26/politics/biden-picket-line-michigan-uaw/index.html'
url5 = 'https://www.cbsnews.com/news/biden-uaw-strike-michigan-picket-line'
html1 = read_html(url1)
html2 = read_html(url2)
html3 = read_html(url3)
html4 = read_html(url4)
html5 = read_html(url5)
scraped_html2 <- html2 %>%
html_elements('.aGjv') %>%
html_text2()
scraped_html2
scraped_html3 <- html3 %>%
html_elements('p:nth-child(30) , :nth-child(25), :nth-child(24), :nth-child(23), :nth-child(17), :nth-child(16), :nth-child(14), :nth-child(13), :nth-child(8), :nth-child(6), .article-body .speakable') %>%
html_text2()
scraped_html3
scraped_html3 <- html3 %>%
html_elements('p:nth-child(25) , :nth-child(24), :nth-child(23), :nth-child(17), :nth-child(16), :nth-child(14), :nth-child(13), :nth-child(8), :nth-child(30), :nth-child(6), .article-body .speakable') %>%
html_text2()
scraped_html3
scraped_html3 <- html3 %>%
html_elements('p:nth-child(25) , :nth-child(24), :nth-child(23), :nth-child(17), :nth-child(16), :nth-child(14), :nth-child(13), .article-body :nth-child(8), :nth-child(30), .article-body :nth-child(6), .article-body .speakable') %>%
html_text2()
scraped_html3
scraped_html3 <- html3 %>%
html_elements('p:nth-child(25) , :nth-child(24), :nth-child(23), :nth-child(17), :nth-child(16), :nth-child(14), :nth-child(13), .article-body :nth-child(8), :nth-child(30), .article-body :nth-child(6), .article-body .speakable')
scraped_html3
scraped_html4 <- html4 %>%
html_elements('.paragraph') %>%
html_text2()
scraped_html4
scraped_html2 <- html2 %>%
html_elements('.aGjv , .ebVH, .pCRh, .home') %>%
html_text2()
html2 = read_html(url2)
library(rvest)
url1 = 'https://www.nbcnews.com/politics/white-house/biden-makes-history-striking-auto-workers-picket-line-rcna117348'
url2 = 'https://abcnews.go.com/Politics/biden-join-striking-auto-workers-picket-line-move/story?id=103470454'
url3 = 'https://www.foxnews.com/us/judge-rules-nyc-migrant-shelter-staten-islands-st-john-villa-academy-must-be-vacated'
url4 = 'https://www.cnn.com/2023/09/26/politics/biden-picket-line-michigan-uaw/index.html'
url5 = 'https://www.cbsnews.com/news/biden-uaw-strike-michigan-picket-line'
html1 = read_html(url1)
html2 = read_html(url2)
html3 = read_html(url3)
html4 = read_html(url4)
html5 = read_html(url5)
scraped_html2 <- html2 %>%
html_elements('.aGjv , .ebVH, .pCRh, .home') %>%
html_text2()
scraped_html2
library(rvest)
url1 = 'https://www.nbcnews.com/politics/white-house/biden-makes-history-striking-auto-workers-picket-line-rcna117348'
url2 = 'https://abcnews.go.com/Politics/biden-join-striking-auto-workers-picket-line-move/story?id=103470454'
url3 = 'https://www.foxnews.com/us/judge-rules-nyc-migrant-shelter-staten-islands-st-john-villa-academy-must-be-vacated'
url4 = 'https://www.cnn.com/2023/09/26/politics/biden-picket-line-michigan-uaw/index.html'
url5 = 'https://www.cbsnews.com/news/biden-uaw-strike-michigan-picket-line'
html1 = read_html(url1)
html2 = read_html(url2)
html3 = read_html(url3)
html4 = read_html(url4)
html5 = read_html(url5)
scraped_html2 <- html2 %>%
html_elements('.home , .aGjv, .ebVH, .Zdbe') %>%
html_text2()
scraped_html2
scraped_html3 <- html3 %>%
html_elements('p:nth-child(30) , :nth-child(25), :nth-child(24), :nth-child(23), :nth-child(17), :nth-child(16), :nth-child(14), :nth-child(13), .article-body :nth-child(8), .article-body :nth-child(6), .article-body .speakable, time')
scraped_html3
scraped_html3 <- html3 %>%
html_elements('p:nth-child(30) , :nth-child(25), :nth-child(24), :nth-child(23), :nth-child(17), :nth-child(16), :nth-child(14), :nth-child(13), .article-body :nth-child(8), .article-body :nth-child(6), .article-body .speakable, time') %>%
html_text2()
scraped_html3
scraped_html3 <- html3 %>%
html_elements('p:nth-child(30) , :nth-child(25), :nth-child(24), :nth-child(23), :nth-child(17), :nth-child(16), :nth-child(14), .article-body :nth-child(13), .article-body :nth-child(8), .article-body :nth-child(6), .article-body .speakable, time') %>%
html_text2()
scraped_html3
scraped_html4 <- html4 %>%
html_elements('.paragraph , .timestamp') %>%
html_text2()
scraped_html4
scraped_html5 <- html5 %>%
html_elements('.content__body p , time') %>%
html_text2()
scraped_html5
class(scraped_html5)
paste(scraped_html5[2:20], collapse = "\n\n")
# Create a new list with the date and the combined text
final_list <- list(html5, scraped_html5[1], combined_text)
combined_text <- paste(scraped_html5[2:20], collapse = "\n\n")
list(html5, scraped_html5[1], combined_text)
list(url5, scraped_html5[1], combined_text)
scraped_html2
combined_text_2 <- paste(scraped_html5[3:25], collapse = "\n\n")
final_list_2 <- list(url2, scraped_html5[2], combined_text_2)
final_list_2
combined_text_2 <- paste(scraped_html5[3:25], collapse = "\n\n")
final_list_2 <- list(url2, scraped_html2[2], combined_text_2)
final_list_2
combined_text_2 <- paste(scraped_html2[3:25], collapse = "\n\n")
final_list_2 <- list(url2, scraped_html2[2], combined_text_2)
final_list_2
scraped_html3
combined_text_3 <- paste(scraped_html3[8:19], collapse = "\n\n")
final_list_3 <- list(url3, scraped_html3[7], combined_text_3)
final_list_3
scraped_html4
sub("Updated ", "", scraped_html4[1]
)
combined_text_4 <- paste(scraped_html4[2:21], collapse = "\n\n")
final_list_4 <- list(url4, sub("Updated ", "", scraped_html4[1]), combined_text_4)
final_list_4
ï¼Ÿread_html
?read_html
getwd()
getwd()
```{r}
shiny::runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
runApp('Documents/GitHub/capstone-project/Capstone project/salary_prediction')
setwd("~/Documents/GitHub/capstone-project/Capstone project/FInal Report")
setwd("~/Documents/GitHub/capstone-project/Capstone project/FInal Report")
setwd("~/Documents/GitHub/capstone-project/Capstone project/Final Report")
runApp('~/Documents/GitHub/capstone-project/Capstone project/salary_prediction')
setwd("~/Documents/GitHub/capstone-project/Capstone project/FInal Report")
setwd("~/Documents/GitHub/capstone-project/Capstone project/Final Report")
